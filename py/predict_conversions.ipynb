{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Conversions from Quotes\n",
    "\n",
    "**Goal**: Build a model to predict whether a quote will convert to a purchase.\n",
    "\n",
    "**Data Sources**\n",
    "* MySQL records of quote details and outcome\n",
    "* Paypal records of flooring samples purchases\n",
    "* Mailchimp subscriber list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bd_mailchimp\n",
    "import bd_paypal\n",
    "import bd_mysql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mailchimp data\n",
    "csv_path = '/Users/lindsay/Documents/Data Science/BrazilianDirect/csv/mailchimp/members_export_21_march_2016.csv'\n",
    "mail, first_email = bd_mailchimp.process_mailchimp(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load paypal data\n",
    "csv_dir = '/Users/lindsay/Documents/Data Science/BrazilianDirect/csv/paypal/'\n",
    "paypal, first_sample = bd_paypal.process_paypal(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load MySQL data\n",
    "config_path = '/Users/lindsay/Documents/Data Science/BrazilianDirect/cfg/mysql.cfg'\n",
    "con = bd_mysql.connect_bd_mysql(config_path)\n",
    "df = bd_mysql.download_quote_data(con)\n",
    "df = bd_mysql.pre_process_mysql(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge mysql & mail chimp\n",
    "df_all = pd.merge(df, mail, how='left', on='email')\n",
    "\n",
    "# add paypal\n",
    "df_all = pd.merge(df_all, paypal, how='left', on='email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace nan with 0\n",
    "df_all['mail_chimp'] = df_all['mail_chimp'].fillna(value=0)\n",
    "df_all['samples'] = df_all['samples'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out quotes before mail chimp & samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20821, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_date = pd.datetime.date(max(first_email, first_sample))\n",
    "df_all = df_all.loc[df_all['date_created'] >= earliest_date, :]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns that won't be used for predictions\n",
    "\n",
    "* `quote_id`: unique identifier\n",
    "* `email`: nearly unique identifier (not many repeat customers)\n",
    "* `date_created`: too fine grained to use\n",
    "* `days_until_needed`: transformed into a binned variable\n",
    "* `ship_state`: transformed into a grouped variable for regions\n",
    "* `install_subfloor`: too many missing values\n",
    "* `sq_ft`: transformed into a binned variable\n",
    "* `milling`: milling is perfectly correlated with `finish` (unfinished = square edge, prefinished = micro bevel)\n",
    "* `year`: interested only in monthly seasonality\n",
    "* `state_division`: will use the regional divisions, which have fewer categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['quote_id',\n",
    "             'email',\n",
    "             'date_created',\n",
    "             'days_until_needed',\n",
    "             'ship_state',\n",
    "             'install_subfloor',\n",
    "             'sq_ft',\n",
    "             'milling',\n",
    "             'year',\n",
    "             'state_division']\n",
    "df_all = df_all.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variables from data fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'phone_provided', u'employee_id', u'cust_price', u'retail_price',\n",
       "       u'common_name', u'finish', u'grade', u'width', u'construction',\n",
       "       u'days_until_needed_bin', u'sq_ft_bin', u'converted', u'month',\n",
       "       u'state_region', u'mail_chimp', u'samples'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column types\n",
    "dependent_column = ['converted']\n",
    "cat_columns = ['phone_provided',\n",
    "               'employee_id',\n",
    "               'common_name',\n",
    "               'finish',\n",
    "               'grade', \n",
    "               'width', \n",
    "               'construction',\n",
    "               'days_until_needed_bin',\n",
    "               'sq_ft_bin',\n",
    "               'month', \n",
    "               'state_region',\n",
    "               'mail_chimp',\n",
    "               'samples']\n",
    "meas_columns = ['cust_price',\n",
    "                'retail_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract variables\n",
    "y = df_all.as_matrix(columns=dependent_column)\n",
    "x_cat = df_all.as_matrix(columns=cat_columns)\n",
    "x_meas = df_all.as_matrix(columns=meas_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical variables to 0-indexed integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "//anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:259: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = {}\n",
    "for i, col in enumerate(cat_columns):\n",
    "    \n",
    "    # Extract the column values and convert to 0-indexed integers\n",
    "    x = x_cat[:, i]\n",
    "    le = LabelEncoder().fit(x)\n",
    "    x_cat[:, i] = le.transform(x)\n",
    "    \n",
    "    # Store label data\n",
    "    labels[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values\n",
    "We'll impute with the median value for the numerical columns that are missing data (`cust_price`) and impute with the mode value for missing categorical data (`days_until_needed_bin` and `sq_ft_bin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_provided :  0\n",
      "employee_id :  0\n",
      "cust_price :  842\n",
      "retail_price :  688\n",
      "common_name :  0\n",
      "finish :  0\n",
      "grade :  0\n",
      "width :  0\n",
      "construction :  0\n",
      "days_until_needed_bin :  10174\n",
      "sq_ft_bin :  3\n",
      "converted :  0\n",
      "month :  0\n",
      "state_region :  0\n",
      "mail_chimp :  0\n",
      "samples :  0\n"
     ]
    }
   ],
   "source": [
    "# Examine number of missing values in each column\n",
    "for col in df_all.columns:\n",
    "    print col, ': ', df_all[col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute measured variables\n",
    "imp_meas = Imputer(missing_values=np.nan, strategy='median', axis=0)\n",
    "\n",
    "# Fit imputer\n",
    "imp_meas.fit(x_meas)\n",
    "\n",
    "# Impute values\n",
    "x_meas_imp = imp_meas.transform(x_meas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute categorical variables\n",
    "imp_cat = Imputer(missing_values=np.nan, strategy='most_frequent', axis=0)\n",
    "\n",
    "# Fit imputer\n",
    "imp_cat.fit(x_cat)\n",
    "\n",
    "# Impute values\n",
    "x_cat_imp = imp_cat.transform(x_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform one-hot encoding on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use one-hot encoding to transform categorical variable into\n",
    "# multiple binary variables\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(x_cat_imp)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "x_cat_imp = enc.transform(x_cat_imp).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list so we know what the one-hot encoded columns refer to\n",
    "one_hot_columns = []\n",
    "for col in cat_columns:\n",
    "    features = list(labels[col].classes_)\n",
    "    for f in features:\n",
    "        one_hot_columns.append(col + '_' + str(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "x_meas_imp = scale(x_meas_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate categorical and continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((x_cat_imp, x_meas_imp), axis=1)\n",
    "x_names = one_hot_columns + meas_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
